龚研
g-gongyan@tedu.cn

python编辑器
anaconda
sublime

课程内容
1.http协议
2.html
2.python基础

1.抓取web网页内容
2.掌握一些简单的反爬措施：设置请求头。设置ip代理
3.掌握抓取信息的抽取技术：xpath，beautifulsoup，pyquery。（正则）

安装：
requests
urllib3

安装模块的方法：
1.file-setting-project [自己定义的文件夹]- project interpreter - + 搜索你需要安装的模块
2.terminal ： pip install requests

bytes 格式的文件 ：字节流


下载的软件：
Fiddler  抓包工具
anaconda python的环境


机器人协议：
简书：www.jianshu.com/robots.txt
虎扑：www.hupu.com/robots.txt

查看网站使用的架构技术：
pip install bulitwith

使用方法：
import builtwith
builtwith.parse("http://www.baidu.com")
{'javascript-frameworks': ['jQuery']}


安装python-whois :
Windows： pip install python-whois
使用：在Python交互环境下，输入：
import whois
whois.whois("http://www.sina.com.cn")

在交互模式下，输入：
>>> import whois
>>> whois.whois('http://www.baidu.com')

url格式：
scheme://host[:port#]/path/…/[?query-string]
[#anchor]
scheme：协议 http https ftp
host：主机名，域名。  www.baidu.com
port：http:80 https：443 ftp：20 21
path：资源的路径：https://www.jianshu.com/u/5d8a174528fd 用户路径
#anchor 锚点 为了更友好的给用户呈现网页内容。
一般锚点属性是：id=“anchor” 或者 name=“anchor”

请求头模块
fake-useragent
安装 pip install fake-useragent

通过httpbin.org 来验证请求头。
{
  "args": {},
  "headers": {
    "Accept": "*/*",
    "Accept-Encoding": "gzip, deflate",
    "Host": "www.httpbin.org",
    "User-Agent": "python-requests/2.14.2"
  },
  "origin": "58.213.152.85, 58.213.152.85",
  "url": "https://www.httpbin.org/get"
}
{
  "args": {},
  "headers": {
    "Accept": "*/*",
    "Accept-Encoding": "gzip, deflate",
    "Host": "www.httpbin.org",
    "User-Agent": "Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/29.0.1547.2 Safari/537.36"
  },
  "origin": "221.226.191.51, 221.226.191.51",
  "url": "https://www.httpbin.org/get"
}

http:请求头
request―method host http版本
request header

http响应头
http版本 status_code pharse
response header
[空行]
响应实体

fiddler


requests库的用法：
requset.get()
requset.post()


xpath语法：
我们从任意节点匹配
//div[@class='r_ls_box']
匹配属性
/@href
/@src
/[@class="something"]
/[@id="something"]

匹配文本
//div/p/a/text()